<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>
	<property>
		<name>dfs.replication</name>
		<value>2</value>
	</property>
	<!-- 重新设置name node 元数据信息存放位置，默认的在tmp下，不可靠 -->
	<property>
		<name>dfs.namenode.name.dir</name>
		<value>/var/bigdata/hadoop/ha/dfs/name</value>
	</property>
	 <!-- 重新设置data node 数据位置，默认的在tmp下，不可靠 -->
	<property>
		<name>dfs.datanode.data.dir</name>
		<value>/var/bigdata/hadoop/ha/dfs/data</value>
	</property>
	 <!-- secondary namenode -->
	<!-- 注释掉SNN，HA不用SNN，standBy做了SNN的事情
        <property>
                <name>dfs.namenode.secondary.http-address</name>
                <value>hadoop-02:50090</value>
        </property>
	-->
	<!-- 配置高可用集群名 -->
	<property>
  		<name>dfs.nameservices</name>
  		<value>mycluster</value>
	</property>
	<!-- 高可用集群里各个namenode的名称 -->
	<property>
  		<name>dfs.ha.namenodes.mycluster</name>
  		<value>nn1,nn2</value>
	</property>
	<!-- 各个namenode的远程过程调用和http地址 -->
	<property>
  		<name>dfs.namenode.rpc-address.mycluster.nn1</name>
  		<value>hadoop-01:8020</value>
	</property>
	<property>
  		<name>dfs.namenode.rpc-address.mycluster.nn2</name>
  		<value>hadoop-02:8020</value>
	</property>
	<property>
  		<name>dfs.namenode.http-address.mycluster.nn1</name>
  		<value>hadoop-01:50070</value>
	</property>
	<property>
  		<name>dfs.namenode.http-address.mycluster.nn2</name>
  		<value>hadoop-02:50070</value>
	</property>
	<!-- Journal node配置，靠mycluster标识集群，一个JN可以伺候多个集群 -->
	<property>
  		<name>dfs.namenode.shared.edits.dir</name>
  		<value>qjournal://hadoop-01:8485;hadoop-02:8485;hadoop-03:8485/mycluster</value>
	</property>
	<!-- Journal Node 把数据写在这里 -->
	<property>
  		<name>dfs.journalnode.edits.dir</name>
  		<value>/var/bigdata/hadoop/ha/dfs/jn</value>
	</property>
	<!-- 在做主备切换的时候哪个类来实现 -->
	<property>
  		<name>dfs.client.failover.proxy.provider.mycluster</name>
  		<value>org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider</value>
	</property>
	<!-- 免密方式调用发送消息 -->
	<property>
  		<name>dfs.ha.fencing.methods</name>
  		<value>sshfence</value>
	</property>
	<property>
  		<name>dfs.ha.fencing.ssh.private-key-files</name>
  		<value>/home/god/.ssh/id_dsa</value>
	</property>
	<!-- 启动HDFS的时候跟Namenode同一节点会启动ZKFC -->
	<property>
   		<name>dfs.ha.automatic-failover.enabled</name>
   		<value>true</value>
 	</property>
	 <!-- snn 检查点 -->
        <!--<property>
                <name>dfs.namenode.checkpoint.dir</name>
                <value>/var/bigdata/hadoop/full/dfs/secondary</value>
        </property>-->
</configuration>
